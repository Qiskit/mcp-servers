{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# Quantum Volume Finder\n\n## A Deep Agent Example for Actual QV Measurement\n\nThis notebook demonstrates a multi-agent system that **finds the highest achievable Quantum Volume** for IBM Quantum backends through **actual hardware execution**.\n\nUnlike simple analysis tools, this agent **runs experiments** and reports **actual results**.\nIt uses a top-down strategy: start at the highest requested depth and work down until it finds a depth that passes the QV criteria.\n\n### What is Quantum Volume?\n\nQuantum Volume (QV) 2^n is **achieved** when:\n- Running n-qubit, depth-n random circuits\n- Heavy Output Probability (HOP) > 2/3\n- HOP = (shots resulting in heavy outputs) / (total shots)\n\n### Two Modes: Quick Test vs Full Protocol\n\n**Single-Circuit Mode** (default): For each depth, generates one random QV circuit, runs it once on hardware, and checks if HOP > 2/3. This gives a quick signal but is **not statistically rigorous**.\n\n**Full QV Protocol** (`NUM_CIRCUITS = 100`): Implements the standard QV protocol ([arXiv:1811.12926](https://arxiv.org/abs/1811.12926)):\n1. Generates N **independent** random QV circuits per depth (each with a different seed)\n2. Runs each circuit on hardware via the `run_qv_depth_trial` batch tool\n3. Computes individual HOP for each circuit\n4. Applies a one-sided confidence interval test: the lower bound of the 97.5% CI of the mean HOP must exceed 2/3\n5. Only then is QV officially \"achieved\" for that depth\n\nSet `NUM_CIRCUITS = 100` (or more) in the configuration cell for official QV certification.\n\n### Strategy: Top-Down Search\n\n1. Start at max_depth (e.g., 5)\n2. Run QV circuit on hardware\n3. Calculate HOP from measurement results\n4. If HOP > 2/3: **SUCCESS!** QV 2^n achieved\n5. If HOP <= 2/3: Try depth-1\n6. Repeat until success or depth 2"
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": "## Architecture\n\n```\n                    QUANTUM VOLUME FINDER\n                      (Coordinator Agent)\n                             |\n          +------------------+------------------+\n          |                  |                  |\n          v                  v                  v\n   BACKEND ANALYST    QUBIT CHAIN         QV EXPERIMENT\n                      OPTIMIZER           RUNNER\n          |                  |                  |\n          v                  v                  v\n   qiskit-ibm-        qiskit-ibm-        transpile_qv_circuit\n   runtime-mcp        runtime-mcp        submit_qv_job\n   (backends)         (QV qubit tools    get_job_status_tool\n                       searches ALL      (local wrappers +\n                       qubits)           MCP tools)\n```\n\n### Data Flow Design\n\nLarge data (QASM circuits, QPY binaries, measurement counts) **never flows through the LLM**.\nLocal tools call MCP tools programmatically and pass data via closures:\n\n- `transpile_qv_circuit(depth, backend, layout)` — generates QV circuit lazily, calls `hybrid_ai_transpile_tool` MCP internally, stores QPY\n- `submit_qv_job(depth, backend, shots)` — reads stored QPY, calls `run_sampler_tool` MCP internally\n- `calculate_hop(job_id, depth)` — calls `get_job_results_tool` MCP internally, looks up heavy outputs\n- `run_qv_depth_trial(depth, backend, layout, num_circuits)` — **full protocol batch tool**: generates N circuits, transpiles, submits, polls, computes HOPs, runs CI test (multi-circuit mode only)\n\n### MCP Tools Used (via wrappers or directly)\n- `get_backend_properties_tool`, `find_optimal_qv_qubits_tool` (runtime MCP, direct)\n- `hybrid_ai_transpile_tool` (transpiler MCP, via `transpile_qv_circuit` / `run_qv_depth_trial`)\n- `run_sampler_tool` (runtime MCP, via `submit_qv_job` / `run_qv_depth_trial`)\n- `get_job_status_tool` (runtime MCP, direct + via `run_qv_depth_trial`)\n- `get_job_results_tool` (runtime MCP, via `calculate_hop` / `run_qv_depth_trial`)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "```bash\n",
    "pip install deepagents langchain langchain-mcp-adapters python-dotenv\n",
    "pip install langchain-anthropic\n",
    "pip install qiskit-mcp-servers\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport os\nimport sys\nfrom datetime import datetime\nfrom typing import Any\n\nfrom deepagents import create_deep_agent\nfrom dotenv import load_dotenv\nfrom langchain_anthropic import ChatAnthropic\nfrom langchain_core.callbacks import BaseCallbackHandler\nfrom langchain_mcp_adapters.client import MultiServerMCPClient\n\n# Load .env (override=True so .env takes precedence over shell env vars)\nload_dotenv(override=True)\n\nprint(\"Configuration:\")\nprint(f\"  QISKIT_IBM_TOKEN: {'Set' if os.getenv('QISKIT_IBM_TOKEN') else 'Not set'}\")\nprint(f\"  ANTHROPIC_API_KEY: {'Set' if os.getenv('ANTHROPIC_API_KEY') else 'Not set'}\")\n\n\n# Callback handler for agent observability\nclass AgentActivityHandler(BaseCallbackHandler):\n    \"\"\"Shows what the agent is doing during execution.\"\"\"\n\n    def __init__(self, verbose: bool = True):\n        self.verbose = verbose\n        self.indent_level = 0\n        self.current_tool = None\n\n    def _timestamp(self) -> str:\n        return datetime.now().strftime(\"%H:%M:%S\")\n\n    def _print(self, msg: str, color: str = \"\") -> None:\n        indent = \"  \" * self.indent_level\n        if color and sys.stdout.isatty():\n            colors = {\n                \"blue\": \"\\033[94m\",\n                \"green\": \"\\033[92m\",\n                \"yellow\": \"\\033[93m\",\n                \"red\": \"\\033[91m\",\n                \"cyan\": \"\\033[96m\",\n                \"magenta\": \"\\033[95m\",\n                \"reset\": \"\\033[0m\",\n            }\n            print(f\"{colors.get(color, '')}{indent}{msg}{colors['reset']}\", flush=True)\n        else:\n            print(f\"{indent}{msg}\", flush=True)\n\n    def on_tool_start(self, serialized: dict | None, input_str: str, **kwargs) -> None:\n        tool_name = serialized.get(\"name\", \"unknown_tool\") if serialized else \"unknown_tool\"\n        self.current_tool = tool_name\n        self._print(f\"\\n[{self._timestamp()}] TOOL: {tool_name}\", \"cyan\")\n        self.indent_level += 1\n        if self.verbose and input_str:\n            input_preview = str(input_str)[:200] + (\"...\" if len(str(input_str)) > 200 else \"\")\n            self._print(f\"Input: {input_preview}\", \"blue\")\n\n    def on_tool_end(self, output: str, **kwargs) -> None:\n        if self.verbose and output:\n            output_preview = str(output)[:300] + (\"...\" if len(str(output)) > 300 else \"\")\n            self._print(f\"Output: {output_preview}\", \"green\")\n        self.indent_level = max(0, self.indent_level - 1)\n        self._print(f\"[{self._timestamp()}] Done: {self.current_tool}\", \"green\")\n\n    def on_tool_error(self, error: Exception, **kwargs) -> None:\n        self.indent_level = max(0, self.indent_level - 1)\n        self._print(f\"[{self._timestamp()}] FAILED: {self.current_tool}: {error}\", \"red\")\n\n    def on_agent_action(self, action, **kwargs) -> None:\n        tool = getattr(action, \"tool\", \"unknown\")\n        self._print(f\"\\n[{self._timestamp()}] Agent calling: {tool}\", \"yellow\")\n\n    def on_agent_finish(self, finish, **kwargs) -> None:\n        self._print(f\"\\n[{self._timestamp()}] Agent finished\", \"green\")\n\n    def on_llm_start(self, serialized: dict | None, prompts: list, **kwargs) -> None:\n        if self.verbose:\n            model = (\n                (serialized.get(\"name\") or serialized.get(\"id\", [\"LLM\"])[-1])\n                if serialized\n                else \"LLM\"\n            )\n            self._print(f\"[{self._timestamp()}] {model} thinking...\", \"blue\")\n\n\ncallback_handler = AgentActivityHandler(verbose=True)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": "COORDINATOR_PROMPT = \"\"\"\n╔══════════════════════════════════════════════════════════════════════════════╗\n║  MANDATORY: task() REQUIRES description PARAMETER - NEVER OMIT IT!           ║\n║                                                                              ║\n║  task(subagent_type=\"X\", description=\"Y\")  ← BOTH parameters REQUIRED        ║\n╚══════════════════════════════════════════════════════════════════════════════╝\n\n╔══════════════════════════════════════════════════════════════════════════════╗\n║  YOU MUST ACTUALLY RUN EXPERIMENTS - NOT JUST ANALYZE OR DOCUMENT!           ║\n║                                                                              ║\n║  DO NOT write reports about \"what you would do\"                              ║\n║  DO NOT say \"ready for execution\" - EXECUTE IT!                              ║\n║  DO NOT create documentation files - SUBMIT JOBS!                            ║\n╚══════════════════════════════════════════════════════════════════════════════╝\n\nYou are the Quantum Volume Finder. Your job is to EXECUTE experiments and report ACTUAL results.\n\n## REQUIRED WORKFLOW (DO ALL STEPS)\n\n1. Get backend info → **backend-analyst**\n2. Find optimal qubits for the depth → **qubit-chain-optimizer**\n3. Run experiment on hardware → **qv-experiment-runner** (transpiles, submits, polls, returns job_id)\n4. Calculate HOP → call calculate_hop(job_id=<job_id>, depth=N)\n5. If HOP above threshold: SUCCESS. If not: try depth-1 (repeat from step 2)\n\n## Subagents — COPY THESE FORMATS EXACTLY\n\n### backend-analyst\n```\ntask(subagent_type=\"backend-analyst\", description=\"Get ibm_boston properties\")\n```\n\n### qubit-chain-optimizer\n```\ntask(subagent_type=\"qubit-chain-optimizer\", description=\"Find 5 optimal qubits for QV-5 on ibm_boston\")\n```\n\n### qv-experiment-runner\nPass depth, backend, and initial_layout (qubits). The subagent transpiles the QV circuit,\nsubmits it to hardware, polls for completion, and returns the job_id.\n```\ntask(subagent_type=\"qv-experiment-runner\", description=\"Run QV experiment: depth=5, backend_name=ibm_boston, initial_layout=[47, 57, 66, 67, 68]\")\n```\n\n## HOP Calculation\n\nAfter the experiment runner returns the job_id:\n1. Call calculate_hop(job_id=<job_id from runner>, depth=N)\n   This fetches the job results and looks up heavy outputs automatically.\n2. Check if above_threshold is true\n\n## Critical Rules\n\n1. DO NOT make recommendations - RUN the experiments\n2. DO NOT stop after one failure - try lower depths\n3. DO NOT limit qubit search - use all qubits on the backend\n4. ALWAYS report actual job ID, measurement counts, and HOP\n\"\"\"\n\nCOORDINATOR_MULTI_CIRCUIT_APPENDIX = \"\"\"\n\n## Multi-Circuit QV Mode (Full Protocol)\n\nYou have the run_qv_depth_trial tool for statistically rigorous QV testing.\nThis runs N independent random circuits per depth and performs the full statistical\nconfidence interval test (arXiv:1811.12926).\n\n### Workflow Change\n- Steps 1-2 are the same (backend analysis, find optimal qubits)\n- Step 3: Instead of qv-experiment-runner, call:\n  run_qv_depth_trial(depth=N, backend_name=<backend>, initial_layout=[q1, q2, ...], num_circuits=<N>, shots=4096)\n  This tool handles everything internally: generates N random circuits, transpiles each,\n  submits each to hardware, polls for completion, computes all HOPs, and runs the\n  statistical CI test. It prints progress as it works.\n- Step 4: Check qv_achieved in the result (replaces manual HOP check)\n  - qv_achieved=true means the lower bound of the 97.5% CI exceeds 2/3 — QV is officially achieved\n  - qv_achieved=false means it failed the statistical test — try depth-1\n- Step 5: If not achieved, try depth-1 (find new optimal qubits first)\n\n### DO NOT use qv-experiment-runner in multi-circuit mode — use run_qv_depth_trial instead.\n\n### Reading Results\n- qv_achieved: true/false (the CI test result)\n- mean_hop: average HOP across all circuits\n- ci_lower: lower bound of 97.5% confidence interval (must be > 2/3 for QV)\n- num_successful: how many circuits completed successfully\n- individual_hops: list of all HOP values\n- message: human-readable summary\n\"\"\"\n\nBACKEND_ANALYST_PROMPT = \"\"\"You are the Backend Analyst, an expert in IBM Quantum hardware.\n\nYour role is to:\n1. List all available quantum backends for the user's account\n2. Get detailed properties for promising backends\n3. Identify backends suitable for Quantum Volume experiments\n4. Report on current queue status and availability\n\nWhen analyzing backends, focus on:\n- Number of qubits (need at least the target QV depth)\n- Quantum volume already achieved\n- Overall system status\n- Queue length (prefer less busy systems)\n\nUse the IBM Runtime MCP tools to gather this information. Report your findings\nin a structured format that the coordinator can use for decision-making.\n\"\"\"\n\nQUBIT_CHAIN_PROMPT = \"\"\"You are the Qubit Chain Optimizer, finding optimal qubits for QV experiments.\n\n## Primary Tool: find_optimal_qv_qubits_tool\n\nThis tool searches the ENTIRE backend (all 127+ qubits) to find the best subgraphs.\nIt does NOT limit to just the first 10 qubits - it analyzes ALL qubits.\n\n### Usage\n```\nfind_optimal_qv_qubits_tool(\n    backend_name=\"ibm_brisbane\",\n    num_qubits=5,       # QV depth\n    num_results=10,     # Get 10 candidates to try\n    metric=\"qv_optimized\"\n)\n```\n\n### Important Parameters\n- **num_qubits**: The QV depth (e.g., 5 for QV-32)\n- **num_results**: Request at least 10 results to have fallback options\n- **metric**: Use \"qv_optimized\" for best QV performance\n\nReturn the top 10 qubit subsets with their scores. The coordinator will use\nthese to run QV experiments, potentially trying multiple if the first fails.\n\"\"\"\n\nQV_EXPERIMENT_RUNNER_PROMPT = \"\"\"You run QV experiments on hardware.\n\nYour task description contains: depth, backend_name, and initial_layout (qubits).\n\n## WORKFLOW — Follow these steps IN ORDER:\n\n### STEP 1: Transpile the QV circuit\n```\ntranspile_qv_circuit(depth=<depth>, backend_name=<backend>, optimization_level=3, initial_layout=<qubits>)\n```\nThis generates the QV circuit and transpiles it. The result shows transpilation metrics.\n\n### STEP 2: Submit to hardware\n```\nsubmit_qv_job(depth=<depth>, backend_name=<backend>, shots=4096)\n```\nThis submits the transpiled circuit. Returns a job_id.\n\n### STEP 3: Wait for completion\nPoll get_job_status_tool(job_id=<id>) every call until job_status is \"DONE\".\n\n### STEP 4: Report back\nReturn ALL of: backend, depth, qubits, job_id, shots.\nThe coordinator will fetch results and calculate HOP using the job_id.\n\"\"\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": "def get_mcp_config():\n    \"\"\"MCP config for QV experiments.\n\n    Note: Only qiskit-ibm-runtime and qiskit-ibm-transpiler are included.\n    qiskit-mcp-server is excluded because hybrid_ai_transpile_tool from\n    qiskit-ibm-transpiler accepts backend_name directly (simpler for agents).\n    \"\"\"\n    return {\n        \"qiskit-ibm-runtime\": {\n            \"transport\": \"stdio\",\n            \"command\": \"qiskit-ibm-runtime-mcp-server\",\n            \"args\": [],\n            \"env\": {\n                \"QISKIT_IBM_TOKEN\": os.getenv(\"QISKIT_IBM_TOKEN\", \"\"),\n                \"QISKIT_IBM_RUNTIME_MCP_INSTANCE\": os.getenv(\"QISKIT_IBM_RUNTIME_MCP_INSTANCE\", \"\"),\n            },\n        },\n        \"qiskit-ibm-transpiler\": {\n            \"transport\": \"stdio\",\n            \"command\": \"qiskit-ibm-transpiler-mcp-server\",\n            \"args\": [],\n            \"env\": {\"QISKIT_IBM_TOKEN\": os.getenv(\"QISKIT_IBM_TOKEN\", \"\")},\n        },\n    }\n\n\ndef generate_qv_circuit_with_ideal_distribution(\n    num_qubits: int,\n    depth: int | None = None,\n    seed: int | None = None,\n) -> dict[str, Any]:\n    \"\"\"Generate a QV circuit and compute its ideal heavy output bitstrings.\"\"\"\n    import logging\n\n    import numpy as np\n    from qiskit import QuantumCircuit\n    from qiskit.circuit.library import quantum_volume\n    from qiskit.qasm3 import dumps\n    from qiskit.quantum_info import Statevector\n\n    logger = logging.getLogger(__name__)\n\n    try:\n        if num_qubits < 2:\n            num_qubits = 2\n        elif num_qubits > 20:\n            logger.warning(\n                f\"QV with {num_qubits} qubits will be slow to simulate. \"\n                \"Consider using <= 20 qubits.\"\n            )\n\n        if depth is None:\n            depth = num_qubits\n        elif depth < 1:\n            depth = 1\n        elif depth > num_qubits:\n            depth = num_qubits\n\n        if seed is None:\n            seed = np.random.randint(0, 2**31)\n\n        qv_circuit = quantum_volume(num_qubits, depth=depth, seed=seed)\n        qv_decomposed = qv_circuit.decompose()\n\n        statevector = Statevector.from_label(\"0\" * num_qubits)\n        final_state = statevector.evolve(qv_decomposed)\n        probabilities = final_state.probabilities()\n\n        ideal_probs = {}\n        for i, prob in enumerate(probabilities):\n            # Format as bitstring matching Qiskit convention (qubit 0 = rightmost)\n            bitstring = format(i, f\"0{num_qubits}b\")\n            ideal_probs[bitstring] = prob\n\n        median_prob = float(np.median(probabilities))\n        heavy_outputs = [bs for bs, prob in ideal_probs.items() if prob > median_prob]\n\n        qv_with_meas = QuantumCircuit(num_qubits, num_qubits)\n        qv_with_meas.compose(qv_decomposed, inplace=True)\n        qv_with_meas.measure(range(num_qubits), range(num_qubits))\n        qasm3_circuit = dumps(qv_with_meas)\n\n        result = {\n            \"status\": \"success\",\n            \"circuit_qasm\": qasm3_circuit,\n            \"num_qubits\": num_qubits,\n            \"depth\": depth,\n            \"seed\": seed,\n            \"heavy_outputs\": heavy_outputs,\n            \"num_heavy_outputs\": len(heavy_outputs),\n            \"median_probability\": median_prob,\n            \"message\": f\"Generated QV-{num_qubits} circuit with {len(heavy_outputs)} heavy outputs\",\n        }\n\n        if num_qubits <= 6:\n            result[\"ideal_probabilities\"] = ideal_probs\n\n        return result\n\n    except Exception as e:\n        logger.error(f\"Failed to generate QV circuit: {e}\")\n        return {\"status\": \"error\", \"message\": f\"Failed to generate QV circuit: {e!s}\"}\n\n\ndef calculate_heavy_output_probability(\n    counts: dict[str, int],\n    heavy_outputs: list[str],\n) -> dict[str, Any]:\n    \"\"\"Calculate the Heavy Output Probability (HOP) for QV validation.\"\"\"\n    import logging\n\n    logger = logging.getLogger(__name__)\n\n    try:\n        if not counts:\n            return {\"status\": \"error\", \"message\": \"No counts provided\"}\n\n        if not heavy_outputs:\n            return {\"status\": \"error\", \"message\": \"No heavy outputs provided\"}\n\n        heavy_set = set(heavy_outputs)\n        total_shots = sum(counts.values())\n        heavy_counts = sum(count for bitstring, count in counts.items() if bitstring in heavy_set)\n\n        hop = heavy_counts / total_shots if total_shots > 0 else 0.0\n        threshold = 2 / 3\n        above_threshold = hop > threshold\n\n        return {\n            \"status\": \"success\",\n            \"heavy_output_probability\": hop,\n            \"total_shots\": total_shots,\n            \"heavy_counts\": heavy_counts,\n            \"num_heavy_bitstrings\": len(heavy_outputs),\n            \"threshold\": threshold,\n            \"above_threshold\": above_threshold,\n            \"message\": f\"HOP = {hop:.4f} ({'above' if above_threshold else 'below'} threshold of {threshold:.4f})\",\n        }\n\n    except Exception as e:\n        logger.error(f\"Failed to calculate HOP: {e}\")\n        return {\"status\": \"error\", \"message\": f\"Failed to calculate HOP: {e!s}\"}\n\n\ndef analyze_qv_experiment_results(\n    hop_values: list[float],\n    confidence_level: float = 0.975,\n) -> dict[str, Any]:\n    \"\"\"Statistical analysis of multiple QV circuit runs (full protocol).\n\n    Used by run_qv_depth_trial in multi-circuit mode. Computes mean HOP,\n    t-distribution CI, and determines if QV is achieved per arXiv:1811.12926.\n    \"\"\"\n    import logging\n\n    import numpy as np\n    from scipy import stats\n\n    logger = logging.getLogger(__name__)\n\n    try:\n        if not hop_values:\n            return {\"status\": \"error\", \"message\": \"No HOP values provided\"}\n\n        hop_array = np.array(hop_values)\n        n = len(hop_array)\n\n        if n < 10:\n            logger.warning(f\"Only {n} HOP values. Recommend at least 100 for statistical significance.\")\n\n        mean_hop = float(np.mean(hop_array))\n        std_hop = float(np.std(hop_array, ddof=1))\n        sem = std_hop / np.sqrt(n)\n\n        t_critical = stats.t.ppf(confidence_level, df=n - 1)\n        ci_lower = mean_hop - t_critical * sem\n        ci_upper = mean_hop + t_critical * sem\n\n        threshold = 2 / 3\n        qv_achieved = bool(ci_lower > threshold)\n        margin = float(ci_lower - threshold)\n\n        if qv_achieved:\n            message = (\n                f\"QV ACHIEVED! Mean HOP = {mean_hop:.4f}, \"\n                f\"CI lower bound = {ci_lower:.4f} > threshold {threshold:.4f}\"\n            )\n        else:\n            message = (\n                f\"QV NOT achieved. Mean HOP = {mean_hop:.4f}, \"\n                f\"CI lower bound = {ci_lower:.4f} <= threshold {threshold:.4f}\"\n            )\n\n        return {\n            \"status\": \"success\",\n            \"qv_achieved\": qv_achieved,\n            \"mean_hop\": mean_hop,\n            \"std_hop\": std_hop,\n            \"standard_error\": sem,\n            \"confidence_interval\": (ci_lower, ci_upper),\n            \"confidence_level\": confidence_level,\n            \"num_circuits\": n,\n            \"threshold\": threshold,\n            \"margin\": margin,\n            \"message\": message,\n        }\n\n    except ImportError as e:\n        return {\"status\": \"error\", \"message\": f\"Missing scipy for statistical analysis: {e!s}\"}\n    except Exception as e:\n        return {\"status\": \"error\", \"message\": f\"Failed to analyze QV results: {e!s}\"}"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": "import asyncio\n\n# Shared cache for QV circuit data — populated lazily by tools\nqv_data: dict[int, dict] = {}\n\n\nasync def create_agent(model: str = \"claude-sonnet-4-20250514\", num_circuits: int = 1):\n    \"\"\"Create the QV Optimizer agent with local tools that wrap MCP calls.\n\n    Args:\n        model: Anthropic model to use\n        num_circuits: Number of independent QV circuits per depth (1=quick, 100+=full protocol)\n    \"\"\"\n    from langchain_core.tools import tool as langchain_tool\n\n    mcp_config = get_mcp_config()\n    mcp_client = MultiServerMCPClient(mcp_config)\n\n    # Load MCP tools from each server\n    server_tools = {}\n    for name in mcp_config:\n        try:\n            tools = await mcp_client.get_tools(server_name=name)\n            server_tools[name] = tools\n            print(f\"{name}: {len(tools)} tools\")\n        except Exception as e:\n            print(f\"{name}: FAILED - {e}\")\n\n    print(f\"\\nTotal MCP tools loaded: {sum(len(t) for t in server_tools.values())}\")\n\n    llm = ChatAnthropic(model=model, temperature=0, max_tokens=8192)\n\n    # Find MCP tools for programmatic use (avoids passing large data through LLM)\n    transpiler_tools = server_tools.get(\"qiskit-ibm-transpiler\", [])\n    runtime_tools = server_tools.get(\"qiskit-ibm-runtime\", [])\n    hybrid_transpile_mcp = next(\n        (t for t in transpiler_tools if t.name == \"hybrid_ai_transpile_tool\"), None\n    )\n    run_sampler_mcp = next(\n        (t for t in runtime_tools if t.name == \"run_sampler_tool\"), None\n    )\n    get_job_results_mcp = next(\n        (t for t in runtime_tools if t.name == \"get_job_results_tool\"), None\n    )\n    get_job_status_mcp = next(\n        (t for t in runtime_tools if t.name == \"get_job_status_tool\"), None\n    )\n\n    def _parse_mcp_result(result) -> dict:\n        \"\"\"Parse the result from a programmatic MCP tool call into a dict.\"\"\"\n        if isinstance(result, list):\n            text = result[0][\"text\"] if result else \"{}\"\n            return json.loads(text)\n        if isinstance(result, str):\n            return json.loads(result)\n        return result\n\n    def _ensure_qv_data(depth: int) -> dict | None:\n        \"\"\"Generate QV circuit data lazily. Returns error dict or None.\"\"\"\n        if depth < 2 or depth > 20:\n            return {\"status\": \"error\", \"message\": f\"Depth must be between 2 and 20, got {depth}\"}\n        if depth not in qv_data:\n            result = generate_qv_circuit_with_ideal_distribution(depth, seed=42 + depth)\n            if result[\"status\"] != \"success\":\n                return result\n            qv_data[depth] = result\n        return None\n\n    # --- Local tools that wrap MCP calls (avoids large data through LLM) ---\n\n    @langchain_tool\n    async def transpile_qv_circuit(\n        depth: int,\n        backend_name: str,\n        optimization_level: int = 3,\n        initial_layout: list[int] | None = None,\n    ) -> dict:\n        \"\"\"Transpile a QV circuit using the AI transpiler.\n\n        Generates the QV circuit on demand and transpiles it via the MCP transpiler.\n        The transpiled QPY is stored internally — call submit_qv_job next.\n\n        Args:\n            depth: The QV depth (e.g., 5 for QV-32, 11 for QV-2048)\n            backend_name: IBM backend name (e.g., 'ibm_boston')\n            optimization_level: Optimization level 1-3 (default: 3)\n            initial_layout: Physical qubits to map virtual qubits to\n        \"\"\"\n        error = _ensure_qv_data(depth)\n        if error:\n            return error\n\n        if hybrid_transpile_mcp is None:\n            return {\"status\": \"error\", \"message\": \"hybrid_ai_transpile_tool not available\"}\n\n        circuit_qasm = qv_data[depth][\"circuit_qasm\"]\n\n        result = await hybrid_transpile_mcp.ainvoke({\n            \"circuit\": circuit_qasm,\n            \"backend_name\": backend_name,\n            \"optimization_level\": optimization_level,\n            \"initial_layout\": initial_layout,\n        })\n\n        result = _parse_mcp_result(result)\n\n        if result.get(\"status\") == \"success\":\n            qv_data[depth][\"circuit_qpy\"] = result[\"circuit_qpy\"]\n            return {\n                \"status\": \"success\",\n                \"depth\": depth,\n                \"backend_name\": backend_name,\n                \"original_circuit\": result.get(\"original_circuit\"),\n                \"optimized_circuit\": result.get(\"optimized_circuit\"),\n                \"improvements\": result.get(\"improvements\"),\n                \"message\": \"Transpiled successfully. Call submit_qv_job next.\",\n            }\n        return result\n\n    @langchain_tool\n    async def submit_qv_job(\n        depth: int,\n        backend_name: str,\n        shots: int = 4096,\n    ) -> dict:\n        \"\"\"Submit a transpiled QV circuit to hardware via the sampler.\n\n        Uses the QPY stored by transpile_qv_circuit — must be called after it.\n\n        Args:\n            depth: The QV depth (must have been transpiled first)\n            backend_name: IBM backend name\n            shots: Number of measurement shots (default: 4096)\n        \"\"\"\n        if depth not in qv_data or \"circuit_qpy\" not in qv_data.get(depth, {}):\n            return {\n                \"status\": \"error\",\n                \"message\": f\"No transpiled circuit for depth {depth}. Call transpile_qv_circuit first.\",\n            }\n\n        if run_sampler_mcp is None:\n            return {\"status\": \"error\", \"message\": \"run_sampler_tool not available\"}\n\n        circuit_qpy = qv_data[depth][\"circuit_qpy\"]\n\n        result = await run_sampler_mcp.ainvoke({\n            \"circuit\": circuit_qpy,\n            \"backend_name\": backend_name,\n            \"shots\": shots,\n        })\n\n        return _parse_mcp_result(result)\n\n    @langchain_tool\n    async def calculate_hop(job_id: str, depth: int) -> dict:\n        \"\"\"Calculate Heavy Output Probability (HOP) for QV validation.\n\n        Fetches job results automatically — just pass the job_id and depth.\n\n        Args:\n            job_id: The job ID from submit_qv_job (e.g., \"d668ng8qbmes739dsh90\")\n            depth: The QV depth — used to look up heavy outputs automatically\n\n        Returns:\n            Dictionary with heavy_output_probability, above_threshold, and message\n        \"\"\"\n        error = _ensure_qv_data(depth)\n        if error:\n            return error\n\n        if get_job_results_mcp is None:\n            return {\"status\": \"error\", \"message\": \"get_job_results_tool not available\"}\n\n        result = await get_job_results_mcp.ainvoke({\"job_id\": job_id})\n        result = _parse_mcp_result(result)\n        if result.get(\"status\") != \"success\":\n            return result\n\n        counts = result[\"counts\"]\n        heavy_outputs = qv_data[depth][\"heavy_outputs\"]\n        return calculate_heavy_output_probability(counts, heavy_outputs)\n\n    @langchain_tool\n    async def run_qv_depth_trial(\n        depth: int,\n        backend_name: str,\n        initial_layout: list[int],\n        num_circuits: int = 100,\n        shots: int = 4096,\n    ) -> dict:\n        \"\"\"Run a full QV trial: N independent circuits at one depth with statistical analysis.\n\n        This is the batch tool for the full QV protocol. It generates N random QV circuits\n        (each with a different seed), transpiles, submits, polls, computes HOPs, and runs\n        the statistical confidence interval test.\n\n        Args:\n            depth: The QV depth to test (e.g., 5 for QV-32)\n            backend_name: IBM backend name (e.g., 'ibm_boston')\n            initial_layout: Physical qubits to map virtual qubits to\n            num_circuits: Number of independent random circuits (default: 100)\n            shots: Number of measurement shots per circuit (default: 4096)\n\n        Returns:\n            Dictionary with qv_achieved, mean_hop, confidence interval, and per-circuit details\n        \"\"\"\n        if hybrid_transpile_mcp is None or run_sampler_mcp is None:\n            return {\"status\": \"error\", \"message\": \"Required MCP tools not available\"}\n        if get_job_results_mcp is None or get_job_status_mcp is None:\n            return {\"status\": \"error\", \"message\": \"Required MCP tools not available\"}\n\n        print(f\"\\n[QV Trial] Starting full QV trial: depth={depth}, {num_circuits} circuits, \"\n              f\"backend={backend_name}, qubits={initial_layout}\")\n\n        # Phase 1: Generate N circuits with different seeds\n        circuits = []\n        for i in range(num_circuits):\n            seed = depth * 1000 + i\n            result = generate_qv_circuit_with_ideal_distribution(depth, seed=seed)\n            if result[\"status\"] != \"success\":\n                return {\"status\": \"error\", \"message\": f\"Failed to generate circuit {i}: {result['message']}\"}\n            circuits.append({\n                \"circuit_qasm\": result[\"circuit_qasm\"],\n                \"heavy_outputs\": result[\"heavy_outputs\"],\n                \"seed\": seed,\n            })\n        print(f\"[QV Trial] Generated {num_circuits} circuits\")\n\n        # Phase 2: Transpile each circuit via MCP (sequential — stdio transport)\n        for i, circ in enumerate(circuits):\n            result = await hybrid_transpile_mcp.ainvoke({\n                \"circuit\": circ[\"circuit_qasm\"],\n                \"backend_name\": backend_name,\n                \"optimization_level\": 3,\n                \"initial_layout\": initial_layout,\n            })\n            result = _parse_mcp_result(result)\n            if result.get(\"status\") != \"success\":\n                return {\"status\": \"error\", \"message\": f\"Failed to transpile circuit {i}: {result.get('message', 'unknown error')}\"}\n            circ[\"circuit_qpy\"] = result[\"circuit_qpy\"]\n            if (i + 1) % 10 == 0 or i == num_circuits - 1:\n                print(f\"[QV Trial] Transpiled {i + 1}/{num_circuits} circuits\")\n\n        # Phase 3: Submit each circuit via MCP (sequential)\n        job_ids = []\n        for i, circ in enumerate(circuits):\n            result = await run_sampler_mcp.ainvoke({\n                \"circuit\": circ[\"circuit_qpy\"],\n                \"backend_name\": backend_name,\n                \"shots\": shots,\n            })\n            result = _parse_mcp_result(result)\n            if result.get(\"status\") != \"success\":\n                return {\"status\": \"error\", \"message\": f\"Failed to submit circuit {i}: {result.get('message', 'unknown error')}\"}\n            job_ids.append(result[\"job_id\"])\n            if (i + 1) % 10 == 0 or i == num_circuits - 1:\n                print(f\"[QV Trial] Submitted {i + 1}/{num_circuits} jobs\")\n\n        # Phase 4: Poll all jobs until completion\n        pending = set(range(num_circuits))\n        failed_jobs = {}\n        while pending:\n            await asyncio.sleep(10)\n            still_pending = set()\n            for idx in pending:\n                result = await get_job_status_mcp.ainvoke({\"job_id\": job_ids[idx]})\n                result = _parse_mcp_result(result)\n                job_status = result.get(\"job_status\", \"UNKNOWN\")\n                if job_status == \"DONE\":\n                    continue\n                elif job_status in (\"ERROR\", \"CANCELLED\"):\n                    failed_jobs[idx] = result.get(\"error_message\", job_status)\n                else:\n                    still_pending.add(idx)\n            pending = still_pending\n            done_count = num_circuits - len(pending) - len(failed_jobs)\n            print(f\"[QV Trial] depth={depth}: {done_count}/{num_circuits} jobs done, \"\n                  f\"{len(pending)} pending, {len(failed_jobs)} failed\")\n\n        # Phase 5: Get results and compute HOPs\n        hop_values = []\n        circuit_results = []\n        for i in range(num_circuits):\n            if i in failed_jobs:\n                circuit_results.append({\n                    \"circuit_index\": i, \"seed\": circuits[i][\"seed\"],\n                    \"job_id\": job_ids[i], \"status\": \"failed\",\n                    \"error\": failed_jobs[i],\n                })\n                continue\n\n            result = await get_job_results_mcp.ainvoke({\"job_id\": job_ids[i]})\n            result = _parse_mcp_result(result)\n            if result.get(\"status\") != \"success\":\n                circuit_results.append({\n                    \"circuit_index\": i, \"seed\": circuits[i][\"seed\"],\n                    \"job_id\": job_ids[i], \"status\": \"error\",\n                    \"error\": result.get(\"message\", \"Failed to get results\"),\n                })\n                continue\n\n            counts = result[\"counts\"]\n            hop_result = calculate_heavy_output_probability(counts, circuits[i][\"heavy_outputs\"])\n            hop = hop_result.get(\"heavy_output_probability\", 0.0)\n            hop_values.append(hop)\n            circuit_results.append({\n                \"circuit_index\": i, \"seed\": circuits[i][\"seed\"],\n                \"job_id\": job_ids[i], \"status\": \"success\",\n                \"hop\": hop, \"above_threshold\": hop_result.get(\"above_threshold\", False),\n            })\n\n        if not hop_values:\n            return {\"status\": \"error\", \"message\": \"All circuits failed — no HOP values collected\"}\n\n        # Phase 6: Statistical analysis\n        analysis = analyze_qv_experiment_results(hop_values)\n\n        print(f\"[QV Trial] depth={depth}: mean_hop={analysis.get('mean_hop', 0):.4f}, \"\n              f\"ci_lower={analysis.get('confidence_interval', (0, 0))[0]:.4f}, \"\n              f\"qv_achieved={analysis.get('qv_achieved', False)}\")\n\n        return {\n            \"status\": \"success\",\n            \"depth\": depth,\n            \"num_circuits\": num_circuits,\n            \"num_successful\": len(hop_values),\n            \"num_failed\": len(failed_jobs),\n            \"qv_achieved\": analysis.get(\"qv_achieved\", False),\n            \"mean_hop\": analysis.get(\"mean_hop\", 0.0),\n            \"std_hop\": analysis.get(\"std_hop\", 0.0),\n            \"ci_lower\": analysis.get(\"confidence_interval\", (0, 0))[0],\n            \"ci_upper\": analysis.get(\"confidence_interval\", (0, 0))[1],\n            \"confidence_level\": analysis.get(\"confidence_level\", 0.975),\n            \"threshold\": 2 / 3,\n            \"individual_hops\": hop_values,\n            \"message\": analysis.get(\"message\", \"\"),\n        }\n\n    # --- Subagent definitions ---\n\n    backend_analyst = {\n        \"name\": \"backend-analyst\",\n        \"description\": \"Expert in IBM Quantum backends. Use this agent to list backends, get properties, find least busy systems, and analyze hardware capabilities.\",\n        \"system_prompt\": BACKEND_ANALYST_PROMPT,\n        \"tools\": server_tools.get(\"qiskit-ibm-runtime\", []),\n    }\n\n    qubit_chain_optimizer = {\n        \"name\": \"qubit-chain-optimizer\",\n        \"description\": \"Expert in qubit topology analysis. Use this agent to find optimal qubit subsets for QV experiments using algorithmic chain/subgraph finding tools.\",\n        \"system_prompt\": QUBIT_CHAIN_PROMPT,\n        \"tools\": server_tools.get(\"qiskit-ibm-runtime\", []),\n    }\n\n    # Runner: local tools + MCP get_job_status_tool for polling\n    runner_mcp_tools = [t for t in runtime_tools if t.name == \"get_job_status_tool\"]\n    qv_experiment_runner = {\n        \"name\": \"qv-experiment-runner\",\n        \"description\": \"Expert in running QV experiments on hardware. Use this agent to transpile circuits, submit jobs, and retrieve results.\",\n        \"system_prompt\": QV_EXPERIMENT_RUNNER_PROMPT,\n        \"tools\": runner_mcp_tools + [transpile_qv_circuit, submit_qv_job],\n    }\n\n    # Coordinator: runtime tools (minus execution/results) + calculate_hop\n    excluded_tools = {\"run_sampler_tool\", \"run_estimator_tool\", \"get_job_results_tool\"}\n    coordinator_tools = [\n        tool for tool in server_tools.get(\"qiskit-ibm-runtime\", [])\n        if tool.name not in excluded_tools\n    ]\n    coordinator_tools.append(calculate_hop)\n\n    # Multi-circuit mode: add batch tool and extended prompt\n    system_prompt = COORDINATOR_PROMPT\n    if num_circuits > 1:\n        coordinator_tools.append(run_qv_depth_trial)\n        system_prompt = COORDINATOR_PROMPT + COORDINATOR_MULTI_CIRCUIT_APPENDIX\n\n    print(f\"\\nMode: {'multi-circuit (' + str(num_circuits) + ' circuits/depth)' if num_circuits > 1 else 'single-circuit'}\")\n    print(f\"Coordinator tools: {len(coordinator_tools)} (excluded: {excluded_tools})\")\n    print(f\"Runner tools: {len(runner_mcp_tools)} MCP + transpile_qv_circuit + submit_qv_job\")\n\n    agent = create_deep_agent(\n        model=llm,\n        tools=coordinator_tools,\n        system_prompt=system_prompt,\n        subagents=[backend_analyst, qubit_chain_optimizer, qv_experiment_runner],\n    )\n\n    print(\"Agent ready!\")\n    return agent\n\n\n# Configuration — change NUM_CIRCUITS to 100+ for full QV protocol\nNUM_CIRCUITS = 1  # 1 = quick test, 100+ = full protocol\n\nagent = await create_agent(num_circuits=NUM_CIRCUITS)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": "# Configuration\nBACKEND = \"ibm_brisbane\"  # Change to your preferred backend\nMAX_DEPTH = 5  # Maximum QV depth to try (starts here, works down)\n\n# Build the request — circuits are generated lazily when the agent requests them\nbackend_section = f\"\"\"\n## Step 1: Backend\nUse backend: **{BACKEND}**\nGet its properties to confirm it's available.\"\"\"\n\nif NUM_CIRCUITS > 1:\n    # Multi-circuit mode: full QV protocol\n    request = f\"\"\"\n# FIND THE HIGHEST ACHIEVABLE QUANTUM VOLUME (Full Protocol — {NUM_CIRCUITS} circuits/depth)\n\nYour task: Find the highest QV this backend can achieve using the full QV protocol\nwith {NUM_CIRCUITS} independent random circuits per depth and statistical CI testing.\n\n{backend_section}\n\n## Step 2: Find Optimal Qubits\nUse qubit-chain-optimizer with find_optimal_qv_qubits_tool(num_qubits=N) for the depth you're testing.\nGet 10 candidate qubit subsets. The tool searches ALL qubits on the backend.\n\n## Step 3: Run Iterative QV Experiments (TOP-DOWN)\n\nSupported depths: 2 through {MAX_DEPTH} (QV {2**2} through QV {2**MAX_DEPTH}).\n\nStart from depth {MAX_DEPTH} and work DOWN:\n\n### For each depth:\n1. Find optimal qubits: task(subagent_type=\"qubit-chain-optimizer\", description=\"Find N optimal qubits for QV-N on {BACKEND}\")\n2. Run full QV trial:\n   run_qv_depth_trial(depth=N, backend_name={BACKEND}, initial_layout=[q1, q2, ...], num_circuits={NUM_CIRCUITS}, shots=4096)\n   This tool runs all {NUM_CIRCUITS} circuits programmatically and returns the statistical result.\n3. Check qv_achieved in the result:\n   - If qv_achieved is true → SUCCESS! QV 2^N is statistically achieved\n   - If qv_achieved is false → try depth N-1\n\n### IMPORTANT:\n- Use run_qv_depth_trial (NOT qv-experiment-runner) for each depth\n- The tool handles transpile, submit, poll, HOP, and CI test internally\n- You MUST try lower depths if higher ones fail\n- STOP when you find a passing depth or reach depth 2\n\"\"\"\nelse:\n    # Single-circuit mode: quick test\n    request = f\"\"\"\n# FIND THE HIGHEST ACHIEVABLE QUANTUM VOLUME\n\nYour task: Find the highest QV this backend can achieve by running experiments.\n\n{backend_section}\n\n## Step 2: Find Optimal Qubits\nUse qubit-chain-optimizer with find_optimal_qv_qubits_tool(num_qubits=N) for the depth you're testing.\nGet 10 candidate qubit subsets. The tool searches ALL qubits on the backend.\n\n## Step 3: Run Iterative QV Experiments (TOP-DOWN)\n\nSupported depths: 2 through {MAX_DEPTH} (QV {2**2} through QV {2**MAX_DEPTH}).\n\nStart from depth {MAX_DEPTH} and work DOWN:\n\n### For each depth:\n1. Find optimal qubits: task(subagent_type=\"qubit-chain-optimizer\", description=\"Find N optimal qubits for QV-N on {BACKEND}\")\n2. Run experiment: task(subagent_type=\"qv-experiment-runner\", description=\"Run QV experiment: depth=N, backend_name={BACKEND}, initial_layout=[q1, q2, ...]\")\n   The runner handles: transpile -> submit -> poll. Returns job_id.\n3. Calculate HOP: calculate_hop(job_id=<job_id from runner>, depth=N)\n4. If above_threshold is true -> SUCCESS! QV 2^N achieved\n5. If above_threshold is false -> try depth N-1\n\n### IMPORTANT:\n- You MUST call qv-experiment-runner for EACH depth you test\n- You MUST call calculate_hop to evaluate results\n- You MUST try lower depths if higher ones fail\n- STOP when you find a passing depth or reach depth 2\n\"\"\"\n\nprint(f\"Starting QV finder for {BACKEND}, max depth {MAX_DEPTH}\")\nif NUM_CIRCUITS > 1:\n    print(f\"Protocol: Full QV ({NUM_CIRCUITS} circuits/depth, 97.5% CI test)\")\nelse:\n    print(\"Protocol: Single-circuit quick test\")\nprint(\"=\" * 70)\n\nresult = await agent.ainvoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": request}]},\n    config={\"callbacks\": [callback_handler]},\n)\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"QV FINDING COMPLETE\")\nprint(\"=\" * 70)\nprint(result.get(\"messages\", [])[-1].content if result.get(\"messages\") else \"No response\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive follow-up with activity logging\n",
    "# Type 'verbose' to toggle detailed logging, 'quit' to exit\n",
    "print(\"Commands: 'quit' to exit, 'verbose' to toggle activity logging\")\n",
    "\n",
    "while True:\n",
    "    query = input(\"You: \").strip()\n",
    "    if query.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        break\n",
    "    if not query:\n",
    "        continue\n",
    "    if query.lower() == \"verbose\":\n",
    "        callback_handler.verbose = not callback_handler.verbose\n",
    "        print(f\"Verbose logging is now {'ON' if callback_handler.verbose else 'OFF'}\\n\")\n",
    "        continue\n",
    "\n",
    "    result = await agent.ainvoke(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "        config={\"callbacks\": [callback_handler]},\n",
    "    )\n",
    "    print(\n",
    "        f\"\\nAssistant: {result.get('messages', [])[-1].content if result.get('messages') else 'No response'}\\n\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}